{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4df86d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# +\n",
    "from dataset.semi import SemiDataset\n",
    "from model.semseg.deeplabv2 import DeepLabV2\n",
    "from model.semseg.deeplabv3plus import DeepLabV3Plus\n",
    "from model.semseg.pspnet import PSPNet\n",
    "from utils import count_params, meanIOU, color_map, Accuracy, DiceCoefficient\n",
    "\n",
    "from utilsf.loss_file import save_loss\n",
    "# -\n",
    "\n",
    "import argparse\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss, DataParallel, functional as F\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4aa2dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "semi_setting = 'kidney/0114'\n",
    "save_path = f'outdir/models/{semi_setting}'\n",
    "pseudo_mask_path = f'outdir/pseudo_masks/{semi_setting}'\n",
    "labeled_id_path = f'dataset/splits/{semi_setting}/labeled.txt'\n",
    "reliable_id_path = f'outdir/reliable_ids/{semi_setting}'\n",
    "data_root = '/tf/dataset/0_data_dataset_voc_950_kidney'\n",
    "batch_size = 4\n",
    "crop_size = 224\n",
    "plus = True\n",
    "dataset ='kidney'\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "if not os.path.exists(pseudo_mask_path):\n",
    "    os.makedirs(pseudo_mask_path)\n",
    "if plus and reliable_id_path is None:\n",
    "    exit('Please specify reliable-id-path in ST++.')\n",
    "\n",
    "criterion = CrossEntropyLoss(ignore_index=255)\n",
    "\n",
    "valset = SemiDataset(dataset, data_root, 'val', None)\n",
    "valloader = DataLoader(valset, batch_size=4 if dataset == 'cityscapes' else 1,\n",
    "                       shuffle=False, pin_memory=True, num_workers=4, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a64d19c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = 'train'\n",
    "\n",
    "trainset = SemiDataset(dataset, data_root, MODE, crop_size, labeled_id_path)\n",
    "trainset.ids = 2 * trainset.ids if len(trainset.ids) < 200 else trainset.ids\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True,\n",
    "                         pin_memory=True, num_workers=16, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c2d3e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_basic_elems():\n",
    "    model_zoo = {'deeplabv3plus': DeepLabV3Plus, 'pspnet': PSPNet, 'deeplabv2': DeepLabV2}\n",
    "    model = model_zoo['deeplabv3plus']('resnet18', 2 if dataset == 'kidney' else 19)\n",
    "\n",
    "    head_lr_multiple = 10.0\n",
    "\n",
    "    optimizer = SGD([{'params': model.backbone.parameters(), 'lr': 0.001},\n",
    "                     {'params': [param for name, param in model.named_parameters()\n",
    "                                 if 'backbone' not in name],\n",
    "                      'lr': 0.001 * head_lr_multiple}],\n",
    "                    lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "    model = DataParallel(model).cuda()\n",
    "\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5eadc2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer = init_basic_elems()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc05b5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, pred, targets, smooth=1):\n",
    "        target_one_hot = F.one_hot(targets, num_classes=pred.shape[1]).permute(0, 3, 1, 2).float()\n",
    "        target_one_hot = target_one_hot[:, 1:, :, :]\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        pred = pred[:, 1:, :, :]  # shape: (16, C-1, 224, 224), e.g. (16, 3, 224, 224) -> (16, 2, 224, 224)\n",
    "        pred = F.sigmoid(pred)\n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        pred_flat = pred.contiguous().view(-1)\n",
    "        target_flat = target_one_hot.contiguous().view(-1)\n",
    "        \n",
    "        intersection = (pred_flat * target_flat).sum()\n",
    "        union = pred_flat.sum() + target_flat.sum()\n",
    "\n",
    "        dice = (2. * intersection + smooth) / (union + smooth)\n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "305eb336",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = DiceLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54db33bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, mask in trainloader:\n",
    "    img, mask = img.to(device), mask.to(device)\n",
    "    pred = model(img)  \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd1b1c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape:  torch.Size([4, 3, 224, 224])\n",
      "mask shape:  torch.Size([4, 224, 224])\n",
      "pred shape:  torch.Size([4, 2, 224, 224])\n",
      "mask min value:  0\n",
      "mask max value:  0\n",
      "pred min value:  -6.024209499359131\n",
      "pred max value:  1.7685109376907349\n"
     ]
    }
   ],
   "source": [
    "print('img shape: ', img.shape)\n",
    "print('mask shape: ', mask.shape)\n",
    "print('pred shape: ', pred.shape)\n",
    "\n",
    "# 檢查 masks 的最小值和最大值\n",
    "print('mask min value: ', mask.min().item())\n",
    "print('mask max value: ', mask.max().item())\n",
    "\n",
    "print('pred min value: ', pred.min().item())\n",
    "print('pred max value: ', pred.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3985247f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.9999886751174927\n"
     ]
    }
   ],
   "source": [
    "loss = criterion(pred, mask)\n",
    "\n",
    "print('Loss: ', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42fc341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0e8fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import CrossEntropyLoss, DataParallel, functional as F\n",
    "\n",
    "\n",
    "# 可視化 pred_classes 的第一個樣本\n",
    "pred_class_sample = pred[0].detach().cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(pred_class_sample, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.title('Predicted Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c6beaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
