{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2647f756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# +\n",
    "from dataset.semi import SemiDataset\n",
    "from model.semseg.deeplabv2 import DeepLabV2\n",
    "from model.semseg.deeplabv3plus import DeepLabV3Plus\n",
    "from model.semseg.pspnet import PSPNet\n",
    "from utils import count_params, meanIOU, color_map, Accuracy, DiceCoefficient\n",
    "\n",
    "from utilsf.loss_file import save_loss\n",
    "# -\n",
    "\n",
    "import argparse\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss, DataParallel, functional as F\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1346e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "semi_setting = 'kidney/0114'\n",
    "save_path = f'outdir/models/{semi_setting}'\n",
    "pseudo_mask_path = f'outdir/pseudo_masks/{semi_setting}'\n",
    "labeled_id_path = f'dataset/splits/{semi_setting}/labeled.txt'\n",
    "reliable_id_path = f'outdir/reliable_ids/{semi_setting}'\n",
    "data_root = '/home/S312112021/dataset/0_data_dataset_voc_950_kidney'\n",
    "batch_size = 16\n",
    "crop_size = 224\n",
    "plus = True\n",
    "dataset ='kidney'\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "if not os.path.exists(pseudo_mask_path):\n",
    "    os.makedirs(pseudo_mask_path)\n",
    "if plus and reliable_id_path is None:\n",
    "    exit('Please specify reliable-id-path in ST++.')\n",
    "\n",
    "criterion = CrossEntropyLoss(ignore_index=255)\n",
    "\n",
    "valset = SemiDataset(dataset, data_root, 'val', None)\n",
    "valloader = DataLoader(valset, batch_size=4 if dataset == 'cityscapes' else 1,\n",
    "                       shuffle=False, pin_memory=True, num_workers=4, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34876898",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = 'train'\n",
    "\n",
    "trainset = SemiDataset(dataset, data_root, MODE, crop_size, labeled_id_path)\n",
    "trainset.ids = 2 * trainset.ids if len(trainset.ids) < 200 else trainset.ids\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True,\n",
    "                         pin_memory=True, num_workers=16, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4ec6f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_basic_elems():\n",
    "    model_zoo = {'deeplabv3plus': DeepLabV3Plus, 'pspnet': PSPNet, 'deeplabv2': DeepLabV2}\n",
    "    model = model_zoo['deeplabv3plus']('resnet18', 2 if dataset == 'kidney' else 19)\n",
    "\n",
    "    head_lr_multiple = 10.0\n",
    "\n",
    "    optimizer = SGD([{'params': model.backbone.parameters(), 'lr': 0.001},\n",
    "                     {'params': [param for name, param in model.named_parameters()\n",
    "                                 if 'backbone' not in name],\n",
    "                      'lr': 0.001 * head_lr_multiple}],\n",
    "                    lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "    model = DataParallel(model).cuda()\n",
    "\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18d5dbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer = init_basic_elems()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "165e24e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義 Dice loss 函數\n",
    "def dice_loss(pred, target, smooth=1e-6):\n",
    "    # 將預測結果應用 softmax 並選取類別 1 的機率\n",
    "    pred = F.softmax(pred, dim=1)\n",
    "    \n",
    "    # 將預測結果和目標轉換為平坦的張量\n",
    "    pred_flat = pred.contiguous().view(-1)\n",
    "    target_flat = target.contiguous().view(-1)\n",
    "    \n",
    "    # 計算交集和聯集\n",
    "    intersection = (pred_flat * target_flat).sum()\n",
    "    union = pred_flat.sum() + target_flat.sum()\n",
    "    \n",
    "    # 計算 Dice loss\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "648c31af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, mask in trainloader:\n",
    "    img, mask = img.to(device), mask.to(device)\n",
    "    pred = model(img)  \n",
    "#     pred = torch.argmax(pred, dim=1)  \n",
    "#     pred = F.softmax(pred, dim=1)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9de9f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape:  torch.Size([16, 3, 224, 224])\n",
      "mask shape:  torch.Size([16, 224, 224])\n",
      "pred shape:  torch.Size([16, 2, 224, 224])\n",
      "mask min value:  0\n",
      "mask max value:  1\n",
      "pred min value:  -2.490520715713501\n",
      "pred max value:  1.966456413269043\n"
     ]
    }
   ],
   "source": [
    "print('img shape: ', img.shape)\n",
    "print('mask shape: ', mask.shape)\n",
    "print('pred shape: ', pred.shape)\n",
    "\n",
    "# 檢查 masks 的最小值和最大值\n",
    "print('mask min value: ', mask.min().item())\n",
    "print('mask max value: ', mask.max().item())\n",
    "\n",
    "print('pred min value: ', pred.min().item())\n",
    "print('pred max value: ', pred.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abe524ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.968191921710968\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "\n",
    "\n",
    "pred = pred[:, 1, :, :]  # 假設第二個通道是我們關注的類別    \n",
    "# loss = criterion(pred, mask)\n",
    "loss = dice_loss(pred, mask)\n",
    "\n",
    "print('Loss: ', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496b25ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ede540f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (2, 224, 224) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m pred_class_sample \u001b[38;5;241m=\u001b[39m pred[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m----> 9\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_class_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mviridis\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mcolorbar()\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted Classes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/pyplot.py:3358\u001b[0m, in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   3337\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mimshow)\n\u001b[1;32m   3338\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimshow\u001b[39m(\n\u001b[1;32m   3339\u001b[0m     X: ArrayLike \u001b[38;5;241m|\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3356\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3357\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AxesImage:\n\u001b[0;32m-> 3358\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3362\u001b[0m \u001b[43m        \u001b[49m\u001b[43maspect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maspect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3363\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3364\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3367\u001b[0m \u001b[43m        \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3369\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation_stage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilternorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilternorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilterrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilterrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3373\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3374\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3375\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3376\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3377\u001b[0m     sci(__ret)\n\u001b[1;32m   3378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/__init__.py:1465\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1464\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1467\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1468\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1469\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/axes/_axes.py:5759\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aspect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5757\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[0;32m-> 5759\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5760\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   5761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5762\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/image.py:723\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(A, PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage):\n\u001b[1;32m    722\u001b[0m     A \u001b[38;5;241m=\u001b[39m pil_to_array(A)  \u001b[38;5;66;03m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[0;32m--> 723\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_normalize_image_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_imcache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/image.py:693\u001b[0m, in \u001b[0;36m_ImageBase._normalize_image_array\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m    691\u001b[0m     A \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# If just (M, N, 1), assume scalar and apply colormap.\u001b[39;00m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]):\n\u001b[0;32m--> 693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for image data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;66;03m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;66;03m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[1;32m    699\u001b[0m     high \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(A\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (2, 224, 224) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import CrossEntropyLoss, DataParallel, functional as F\n",
    "\n",
    "\n",
    "# 可視化 pred_classes 的第一個樣本\n",
    "pred_class_sample = pred[0].detach().cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(pred_class_sample, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.title('Predicted Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1dd01b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
